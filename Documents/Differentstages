Early stage (low ID blocks, low confidence)

Sparse knowledge, lots of gaps
System is mostly in research/acquisition mode
Can't do much reasoning because there's not enough to reason with
Heavy reliance on external sources, careful about making claims

Mid stage (growing block count, mixed confidence)

Learning as it goes
Starting to connect blocks, noticing patterns
Can answer some things confidently, flags others as uncertain
Building up the relational structure

Late stage (high block count, high confidence network)

Rich interconnected knowledge
LLM can actually do the interesting stuff: manipulate, reason across layers, find analogies via functional roles
Cross-domain inference becomes possible because the foundation is solid
System can be more "generative" in its reasoning without risking hallucination
